# Local LLM Documentation

Welcome to the Local LLM Documentation. This guide will assist you in setting up, configuring, and optimizing local Large Language Models using Roo Code.

## Overview

This documentation is organized into several sections. Choose the path that best meets your needs:

## Quick Start

### Basic Setup and Verification
1. [Quick Start Overview](quick-start/local-llm-quick-path.md)
2. [Hardware Requirements](quick-start/hardware-requirements.md)
3. [Model Selection Guide](quick-start/model-selection.md)
4. [Tool Usage Guide](quick-start/tool-usage.md)
5. [Setup Verification](quick-start/setup-verification.md)
6. [Troubleshooting](quick-start/troubleshooting.md)

## Advanced Configuration

For detailed advanced configuration and optimization topics, refer to:
1. [Architecture Deep Dive](advanced/architecture.md)
2. [Hardware Optimization](advanced/hardware-optimization.md)
3. [Model Selection Guide](advanced/model-selection-guide.md)
4. [Model Tuning](advanced/model-tuning.md)
5. [LLM Runner Comparison](advanced/llm-runner-comparison.md)
6. [Prompt Engineering](advanced/prompt-engineering-new.md)
7. [Token Management](advanced/token-management.md)
8. [Tool Architecture](advanced/tool-architecture.md)
9. [Tool Invocation](advanced/tool-invocation.md)
10. [Advanced Troubleshooting](advanced/advanced-troubleshooting.md)

## Reference

- [Glossary](reference/glossary.md)

## Contributing

We welcome contributions. Please submit issues or pull requests for content improvements.

## Need Help?

- For community support, visit our Discord server.
- Check the [Glossary](reference/glossary.md) for terminology.
- Contact the development team for critical issues.